{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_bfgs, fmin_l_bfgs_b\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import hashlib\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('categories.txt', 'rb') as content_file:\n",
    "    categories = content_file.read().split('\\n')\n",
    "#to make things faster i put the index where every category starts in a dictionary where the key are the product ids and \n",
    "#the values are the starting index of the category\n",
    "catindex = defaultdict(int)\n",
    "f = open('categories.txt','rb')\n",
    "for i,l in enumerate(f):\n",
    "    if len(l)-len(l.strip()) <=1:\n",
    "        catindex[l.strip()]=i\n",
    "        \n",
    "#takes product id and returns category\n",
    "def getCategory(pid, categories, catdict, depth):\n",
    "    index = catdict[pid]\n",
    "    value = set()\n",
    "    j = index + 1\n",
    "    while len(categories[j])-len(categories[j].strip())>1:\n",
    "                ws = (categories[j].strip()).split(',')\n",
    "                break\n",
    "    return str((ws[:depth])[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('100 core subset filtered.csv', 'rb') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data.append((row['uid'], row['pid'], float(row['rating']), row['time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('A1YXHALQFWN45C', '0783885008', 4.0, '1288310400'), 67046)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0], len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gethexdig(txt):\n",
    "    c = hashlib.md5(txt.encode())\n",
    "    return c.hexdigest()\n",
    "\n",
    "gs= defaultdict(int)\n",
    "for d in data:\n",
    "    cat = getCategory(d[1], categories, catindex, 3)\n",
    "    gs[cat]+=1\n",
    "gs = set(sorted(gs.iteritems(), key= operator.itemgetter(1), reverse=True)[:50])\n",
    "ghashed = set()\n",
    "for g in gs:\n",
    "    ghashed.add(gethexdig(g[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itemsuserrated = defaultdict(lambda: list())\n",
    "useritems = defaultdict(lambda: list())\n",
    "itemsuserratedwithtime = defaultdict(lambda: list())\n",
    "for d in data:\n",
    "    itemsuserrated[d[0]].append((d[1], d[3]))\n",
    "\n",
    "for u in itemsuserrated:\n",
    "    items = itemsuserrated[u]\n",
    "    isorted = sorted(items, key = lambda tup: tup[1])\n",
    "    itemsuserrated[u] = isorted\n",
    "    useritems[u] = [i[0] for i in isorted]\n",
    "    itemsuserratedwithtime[u] = [(i[0], i[1]) for i in isorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datag = []\n",
    "depth = 3\n",
    "count = 0\n",
    "dg = 'anything'\n",
    "for d in data:\n",
    "    index = list(useritems[d[0]]).index(d[1])\n",
    "    cgenre = getCategory(d[1],categories,catindex,depth)\n",
    "    if gethexdig(cgenre) not in ghashed:\n",
    "        cgenre = dg\n",
    "    if not index==0:\n",
    "        pgenre = getCategory(list(useritems[d[0]])[index-1], categories, catindex, depth)\n",
    "        if gethexdig(pgenre) not in ghashed:\n",
    "            pgenre = dg\n",
    "        tup = (d[:3] + (cgenre, pgenre))\n",
    "    else: \n",
    "        tup = (d[:3] + (cgenre,))\n",
    "    datag.append(tup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A1YXHALQFWN45C', '0783885008', 4.0, 'Historical', 'Food & Wine')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datag[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = {}\n",
    "products = {}\n",
    "us = set()\n",
    "ps = set()\n",
    "genres = defaultdict(int)\n",
    "gs  = set()\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "for d in datag:\n",
    "    if d[0] not in us:\n",
    "        users[d[0]] = i\n",
    "        i+=1\n",
    "        us.add(d[0])\n",
    "    if d[1] not in ps:\n",
    "        products[d[1]] = j\n",
    "        j+=1\n",
    "        ps.add(d[1])\n",
    "    if d[3] not in gs:\n",
    "        gs.add(d[3])\n",
    "        genres[d[3]] = k\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357, 357, 51)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itemsuserrated), len(users), len(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # datag = list(set(datag))\n",
    "# # np.random.shuffle(datag)\n",
    "# dtest = []\n",
    "# dt = set()\n",
    "# dv = set()\n",
    "# dvalid= [] #to choose best regualrization parameter and dimninsionality of factor vectors \n",
    "# dtestusers = defaultdict(int)\n",
    "# dvalidusers = defaultdict(int)\n",
    "# for d in datag:\n",
    "#     cr = len(itemsuserrated[d[0]])\n",
    "#     vc = int((cr * 20)/float(100))\n",
    "#     if dtestusers[d[0]]< vc:\n",
    "#         dtestusers[d[0]] +=1\n",
    "#         dt.add(d)\n",
    "#         dtest.append(d)\n",
    "#     if d not in dt and dvalidusers[d[0]]<vc:\n",
    "#         dvalidusers[d[0]]+=1\n",
    "#         dv.add(d)\n",
    "#         dvalid.append(d)\n",
    "\n",
    "# dtrain = []\n",
    "# for d in datag:\n",
    "#     if d not in dt and d not in dv:\n",
    "#         dtrain.append(d)\n",
    "# dtrain = list(dtrain)\n",
    "# dtest = list(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40227 13409 13410 67046\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x60 = int((len(datag) * 60) / float(100))\n",
    "x20 = int((len(datag) * 20) / float(100))\n",
    "dtrain = datag[:x60]\n",
    "dvalid = datag[x60: x60+ x20]\n",
    "end =  x60+ x20\n",
    "dtest = datag[end:]\n",
    "print len(dtrain), len(dvalid), len(dtest), len(datag)\n",
    "print len(dtrain) + len(dvalid) + len(dtest) == len(datag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A1YXHALQFWN45C', '0783885008', 4.0, 'Historical', 'Food & Wine')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357 50123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(users), len(products)\n",
    "len(dtrain)+ len(dtest)+ len(dvalid) == len(datag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gside = len(genres)\n",
    "gside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k = 1\n",
    "# lam = 10\n",
    "# s = 0\n",
    "# for d in datag:\n",
    "#     s+= d[2]\n",
    "# alpha = s / float(len(data))\n",
    "# betau = np.random.normal(0,0.1, len(users))\n",
    "# betai = np.random.normal(0,0.1, len(products))\n",
    "# betagg = np.random.normal(0,0.1, (gside, gside))\n",
    "# initial = [alpha] + list(betau) + list(betai) + list(betagg.flatten())\n",
    "# gammu = np.random.normal(0,0.1, (len(users), k)) \n",
    "# gammi = np.random.normal(0,0.1, (len(products), k)) \n",
    "# initial= initial + list(gammu.flatten()) + list(gammi.flatten())\n",
    "# compute_cost(initial, 0, 1, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "us = set()\n",
    "ps = set()\n",
    "gs = set()\n",
    "for d in datag:\n",
    "    us.add(d[0])\n",
    "    ps.add(d[1])\n",
    "    for i in xrange(4, len(d)):\n",
    "        gs.add((d[i], d[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uintrain = set()\n",
    "pintrain = set()\n",
    "gintrain = set()\n",
    "for d in dtrain:\n",
    "    pintrain.add(d[1])\n",
    "    uintrain.add(d[0])\n",
    "    for i in xrange(4, len(d)):\n",
    "        gintrain.add((d[i], d[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2322 2077\n"
     ]
    }
   ],
   "source": [
    "print len(gs), len(gintrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPredictions(params,k, data):\n",
    "    alphao = params[0]\n",
    "    betauo = params[1: len(users)+1]\n",
    "    end = len(users)+1\n",
    "    betaio = params[end: end+len(products)]\n",
    "    end = end+len(products)\n",
    "    bij = np.array(params[end: end+(gside**2)])\n",
    "    betaggo = bij.reshape(gside, gside)\n",
    "    end = end + (gside**2)\n",
    "    gss = np.array(params[end:])\n",
    "    gr = gss.reshape(len(users)+len(products),k)\n",
    "    gammuo = gr[:len(users),:]\n",
    "    gammio = gr[len(users):,:]\n",
    "    predictions = []\n",
    "    for d in data:\n",
    "        pred = alphao + betauo[users[d[0]]] + betaio[products[d[1]]] + (gammuo[users[d[0]]].T.dot(gammio[products[d[1]]]))\n",
    "        for i in xrange(4, len(d)):\n",
    "            pred += betaggo[genres[d[i]]][genres[d[3]]]\n",
    "        predictions.append(pred)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse(params,k, data):\n",
    "    s = 0\n",
    "    predictions = getPredictions(params, k, data)\n",
    "    for i, d in enumerate(data):\n",
    "        s+= (predictions[i] - d[2])**2\n",
    "    return s / float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(data):\n",
    "    s = 0\n",
    "    for d in data:\n",
    "        s+= int(d[2])\n",
    "    return  s/ float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.161471228708648"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variance(data):\n",
    "    m = mean(data)\n",
    "    s = 0\n",
    "    for d in data:\n",
    "        s += (m - d[2]) ** 2\n",
    "    return s/float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Rsquare_statistic(params,k, data):\n",
    "    predictions = getPredictions(params,k, data)\n",
    "    error = mse(params,k, data)\n",
    "    var = variance(data)\n",
    "    return error/float(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(params,k,data):\n",
    "    predictions = getPredictions(params, k, data)\n",
    "    s = 0\n",
    "    for i, d in enumerate(data):\n",
    "        s+= (predictions[i] - d[2])**2\n",
    "    return math.sqrt(s / float(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_cost(initial,lam1, lam2,k, data):\n",
    "    alpha = initial[0]\n",
    "    betau = initial[1:len(users) + 1]\n",
    "    end = len(users)+1\n",
    "    betai = initial[end:end + len(products)]\n",
    "    end = end + len(products)\n",
    "    bij = np.array(initial[end: end+(gside**2)])\n",
    "    betagg = bij.reshape(gside, gside)\n",
    "    end = end + (gside**2)\n",
    "    gss = np.array(initial[end:])\n",
    "    gr = gss.reshape(len(users)+len(products),k)\n",
    "    gammu = gr[:len(users),:]\n",
    "    gammi = gr[len(users):,:]\n",
    "    J = 0\n",
    "    for d in data:\n",
    "        term = (alpha + betau[users[d[0]]] + betai[products[d[1]]] + (gammu[users[d[0]]].T.dot(gammi[products[d[1]]])) - d[2])\n",
    "        for i in xrange(4, len(d)):\n",
    "            term += betagg[genres[d[i]]][genres[d[3]]]\n",
    "        J+= (term ** 2)\n",
    "    for u in us:\n",
    "        J += lam1 * (np.square(betau[users[u]])+ np.sum(np.square(gammu[users[u]])))\n",
    "    for p in ps:\n",
    "        J+= lam1 * (np.square(betai[products[p]]) + np.sum(np.square(gammi[products[p]])))\n",
    "    for g in gintrain:\n",
    "        J+= lam2 * np.square(betagg[genres[g[0]]][genres[g[1]]])\n",
    "    g = compute_gradient(alpha, betau, betai, betagg, gammu, gammi,lam1, lam2,k, data)\n",
    "#     print J\n",
    "    return J,g.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(initial,k, data):\n",
    "    alpha = initial[0]\n",
    "    betau = initial[1:len(users) + 1]\n",
    "    end = len(users)+1\n",
    "    betai = initial[end:end + len(products)]\n",
    "    end = end + len(products)\n",
    "    bij = np.array(initial[end: end+(gside**2)])\n",
    "    betagg = bij.reshape(gside, gside)\n",
    "    end = end + (gside**2)\n",
    "    gss = np.array(initial[end:])\n",
    "    gr = gss.reshape(len(users)+len(products),k)\n",
    "    gammu = gr[:len(users),:]\n",
    "    gammi = gr[len(users):,:]\n",
    "    J = 0\n",
    "    for d in data:\n",
    "        term = (alpha + betau[users[d[0]]] + betai[products[d[1]]] + (gammu[users[d[0]]].T.dot(gammi[products[d[1]]])) - d[2])\n",
    "        for i in xrange(4, len(d)):\n",
    "            term += betagg[genres[d[i]]][genres[d[3]]]\n",
    "        J+= (term ** 2)\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_gradient(alpha,betau, betai,betagg, gammu, gammi,lam1, lam2,k, data):\n",
    "    ga = 0\n",
    "    gbu = np.zeros(len(users))\n",
    "    gbi = np.zeros(len(products))\n",
    "    ggu = np.zeros((len(users),k))\n",
    "    ggi = np.zeros((len(products),k))\n",
    "    gbgg = np.zeros((gside, gside))\n",
    "    for d in data:\n",
    "        term = (alpha + betau[users[d[0]]] + betai[products[d[1]]] + (gammu[users[d[0]]].T.dot(gammi[products[d[1]]])) - d[2])\n",
    "        for i in xrange(4, len(d)):\n",
    "            term += betagg[genres[d[i]]][genres[d[3]]]\n",
    "        ga+= 2 * term\n",
    "        gbu[users[d[0]]] += 2 * term\n",
    "        gbi[products[d[1]]] += 2 * term\n",
    "        ggu[users[d[0]]] += 2 * gammi[products[d[1]]] * term\n",
    "        ggi[products[d[1]]] += 2 * gammu[users[d[0]]] * term\n",
    "        for i in xrange(4, len(d)):\n",
    "            gbgg[genres[d[i]]][genres[d[3]]] += 2* term\n",
    "    for u in us:\n",
    "        gbu[users[u]] += 2 * lam1 * betau[users[u]]\n",
    "        ggu[users[u]] += 2 * lam1 * gammu[users[u]]\n",
    "    for p in ps:\n",
    "        gbi[products[p]] += 2 * lam1 * betai[products[p]]\n",
    "        ggi[products[p]] += 2 * lam1 * gammi[products[p]]\n",
    "    for g in gs:\n",
    "        gbgg[genres[g[0]]][genres[g[1]]] += 2 * lam2 * betagg[genres[g[0]]][genres[g[1]]]\n",
    "    return np.array([ga] + list(gbu) + list(gbi) + list(gbgg.flatten()) + list(ggu.flatten())+ list(ggi.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "s = 0\n",
    "for d in data:\n",
    "    s+= d[2]\n",
    "alpha = s / float(len(data))\n",
    "betau = np.random.normal(0,0.1, len(users))\n",
    "betai = np.random.normal(0,0.1, len(products))\n",
    "betagg = np.random.normal(0,0.1, (gside, gside))\n",
    "gammu = np.random.normal(0,0.1, (len(users), k)) \n",
    "gammi = np.random.normal(0,0.1, (len(products), k)) \n",
    "for u in users:\n",
    "    if u not in uintrain:\n",
    "        betau[users[u]] = 0\n",
    "        gammu[users[u]] = 0\n",
    "\n",
    "for p in products:\n",
    "    if p not in pintrain:\n",
    "        betai[products[p]] = 0\n",
    "        gammi[products[p]] = 0\n",
    "\n",
    "for g in gs:\n",
    "    if g not in gintrain:\n",
    "        betagg[genres[g[0]]][genres[g[1]]] = 0\n",
    "\n",
    "initial = [alpha] + list(betau) + list(betai) + list(betagg.flatten()) + list(gammu.flatten()) + list(gammi.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class ConvergedException(Exception):\n",
    "#     pass\n",
    "# def check(xk):\n",
    "#     global result\n",
    "#     global minmse\n",
    "#     global count\n",
    "#     global presult\n",
    "#     global nit \n",
    "    \n",
    "#     nit +=1\n",
    "# #     print nit\n",
    "\n",
    "#     cmse = mse(xk,k, dvalid)\n",
    "    \n",
    "#     if cmse > minmse:\n",
    "#         if nit >= 100:\n",
    "#             count +=1\n",
    "#             if count == 5:\n",
    "#                 print 'here'\n",
    "#                 result[:] = presult\n",
    "#                 raise ConvergedException()\n",
    "#                 return\n",
    "\n",
    "#     else:\n",
    "#         minmse = cmse\n",
    "#         presult[:] = xk\n",
    "#         count = 0\n",
    "# #     print cmse, minmse, presult[0]\n",
    "#     return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvergedException(Exception):\n",
    "    pass\n",
    "def check_updated(xk):\n",
    "    global result\n",
    "    global minmse\n",
    "    global count\n",
    "    global presult\n",
    "    global nit \n",
    "    \n",
    "    nit +=1\n",
    "#     print nit\n",
    "\n",
    "#     cmse = mse(xk,k, dvalid)\n",
    "    cmse = cost(xk, k, dvalid)\n",
    "    if cmse > minmse:\n",
    "            count +=1\n",
    "            if count == 30:\n",
    "                print 'here'\n",
    "                result[:] = presult\n",
    "                raise ConvergedException()\n",
    "                return\n",
    "\n",
    "    else:\n",
    "        minmse = cmse\n",
    "        presult[:] = xk\n",
    "        count = 0\n",
    "#     print cmse, minmse, presult[0]\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "converged61\n",
      "lambda \"10\" -> \"0\" :  10488.337303 10275.8192303 0.782186389961 0.76628033037\n",
      "here\n",
      "converged61\n",
      "lambda \"10\" -> \"0.0001\" :  10488.3348074 10275.8163691 0.782186203845 0.766280117009\n",
      "here\n",
      "converged61\n",
      "lambda \"10\" -> \"0.001\" :  10488.3123511 10275.7906198 0.78218452913 0.766278196854\n",
      "here\n",
      "converged61\n",
      "lambda \"10\" -> \"0.01\" :  10488.0882234 10275.5332556 0.78216781441 0.766259004891\n",
      "here\n",
      "converged61\n",
      "lambda \"10\" -> \"0.1\" :  10485.8896221 10272.976665 0.782003849811 0.766068356822\n",
      "here\n",
      "converged61\n",
      "lambda \"10\" -> \"1\" :  10465.6257189 10249.8994118 0.780492633221 0.764347458001\n",
      "here\n",
      "converged65\n",
      "lambda \"10\" -> \"10\" :  10377.8202943 10148.4927598 0.77394438767 0.756785440702\n",
      "here\n",
      "converged94\n",
      "lambda \"10\" -> \"100\" :  10314.3545837 10103.9027631 0.769211319538 0.753460310445\n",
      "here\n",
      "converged78\n",
      "lambda \"10\" -> \"1000\" :  10329.0007385 10113.2821639 0.770303582553 0.754159743768\n",
      "here\n",
      "converged113\n",
      "lambda \"10\" -> \"10000\" :  10334.2942251 10110.5908403 0.770698353726 0.753959048493\n",
      "here\n",
      "converged46\n",
      "lambda \"10\" -> \"100000\" :  10997.6592433 10801.1757388 0.820169978616 0.805456803789\n"
     ]
    }
   ],
   "source": [
    "lams1 = [10]\n",
    "lams2 = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "for l1 in lams1:\n",
    "    for l2 in lams2:\n",
    "        minmse = 1000000000000000\n",
    "        presult = []\n",
    "        count = 0\n",
    "        nit = 0\n",
    "        result = []\n",
    "        params = []\n",
    "        try:\n",
    "            params, c,d = fmin_l_bfgs_b(compute_cost, x0=initial,args=(l1, l2,k, dtrain, ), disp = 0, callback = check_updated)\n",
    "            params[:] = presult\n",
    "        except ConvergedException:\n",
    "            params[:] = result\n",
    "        print 'converged' + str(nit)\n",
    "        print \"lambda \"+ '\"' +  str(l1) + '\" -> \"' + str(l2) + '\" : ' + ' ' + str(cost(params, k, dvalid)) + ' ' + str(cost(params,k, dtest)) + ' ' +  str(mse(params, k, dvalid)) + ' ' + str(mse(params,k, dtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "lams = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "x = lams\n",
    "y = [0.782691640296 , 0.78269300387  , 0.782707711788  , 0.782389661747  , 0.783028716481 , 0.781518211899, 0.77358537001,\n",
    "     0.768996194757 , 0.769847381673, 0.770736449983 , 0.80777145789 \n",
    "    ]\n",
    "plt.scatter(lams[7], y[7], color = 'black', s = 100, marker=\"o\")\n",
    "plt.semilogx(x, y, color = 'red')\n",
    "plt.xlabel('Lambda Value For Adjacent Genre Bias Terms')\n",
    "plt.ylabel('mse on Validation Set')\n",
    "plt.title(\"Adjacent Pairwise Genre Bias Terms Model Regularization Parameter vs. mse\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "converged73\n",
      "lambda \"10\" -> \"0\" :  0.782663790376, 0.765423822909\n",
      "here\n",
      "converged73\n",
      "lambda \"10\" -> \"0.0001\" :  0.78266369207, 0.765425618876\n",
      "here\n",
      "converged73\n",
      "lambda \"10\" -> \"0.001\" :  0.78266313332, 0.765442903214\n",
      "here\n",
      "converged72\n",
      "lambda \"10\" -> \"0.01\" :  0.782672024304, 0.765625225481\n",
      "here\n",
      "converged73\n",
      "lambda \"10\" -> \"0.1\" :  0.782482471001, 0.765606061292\n",
      "here\n",
      "converged73\n",
      "lambda \"10\" -> \"1\" :  0.7815432061, 0.764626843147\n",
      "here\n",
      "converged110\n",
      "lambda \"10\" -> \"10\" :  0.773519620686, 0.756809869323\n",
      "here\n",
      "converged91\n",
      "lambda \"10\" -> \"100\" :  0.768832602376, 0.753051600261\n",
      "here\n",
      "converged136\n",
      "lambda \"10\" -> \"1000\" :  0.76979610544, 0.752800736982\n",
      "here\n",
      "converged114\n",
      "lambda \"10\" -> \"10000\" :  0.771090234186, 0.754196350854\n",
      "here\n",
      "converged43\n",
      "lambda \"10\" -> \"100000\" :  0.80152495266, 0.787062305622\n"
     ]
    }
   ],
   "source": [
    "lams1 = [10]\n",
    "lams2 = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "for l1 in lams1:\n",
    "    for l2 in lams2:\n",
    "        minmse = 1000000000000000\n",
    "        presult = []\n",
    "        count = 0\n",
    "        nit = 0\n",
    "        result = []\n",
    "        params = []\n",
    "        try:\n",
    "            params, c,d = fmin_l_bfgs_b(compute_cost, x0=initial,args=(l1, l2,k, dtrain, ), disp = 0, callback = check_updated)\n",
    "            params[:] = presult\n",
    "        except ConvergedException:\n",
    "            params[:] = result\n",
    "        print 'converged' + str(nit)\n",
    "        print \"lambda \"+ '\"' +  str(l1) + '\" -> \"' + str(l2) + '\" : ' + ' ' + str(mse(params, k, dvalid)) + ', ' + str(mse(params, k, dtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "0.753883940781\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pms, c,d = fmin_l_bfgs_b(compute_cost, x0=initial,args=(10,1000,k, dtrain, ), disp = 0, callback = check_updated)\n",
    "except ConvergedException:\n",
    "    pms = result\n",
    "print mse(pms, k, dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "converged104\n",
      "lambda \"10\" -> \"0\" :  0.766153915529\n",
      "here\n",
      "converged104\n",
      "lambda \"10\" -> \"0.0001\" :  0.766260425001\n",
      "here\n",
      "converged104\n",
      "lambda \"10\" -> \"0.001\" :  0.766658491669\n",
      "here\n",
      "converged104\n",
      "lambda \"10\" -> \"0.01\" :  0.766684247062\n",
      "here\n",
      "converged104\n",
      "lambda \"10\" -> \"0.1\" :  0.766381137135\n",
      "here\n",
      "converged104\n",
      "lambda \"10\" -> \"1\" :  0.76430908397\n",
      "here\n",
      "converged104\n",
      "lambda \"10\" -> \"10\" :  0.756883829114\n",
      "here\n",
      "converged108\n",
      "lambda \"10\" -> \"100\" :  0.753114112668\n",
      "here\n",
      "converged104\n",
      "lambda \"10\" -> \"1000\" :  0.753286957465\n",
      "here\n",
      "converged104\n",
      "lambda \"10\" -> \"10000\" :  0.754408602709\n",
      "here\n",
      "converged108\n",
      "lambda \"10\" -> \"100000\" :  0.754930544152\n"
     ]
    }
   ],
   "source": [
    "lams1 = [10]\n",
    "lams2 = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "# with open('Regression baseline - Adjacent pair wise genre bias terms 100 core more.csv', 'wb') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['lambda1', 'lambda2','k','value'])\n",
    "    writer.writeheader()\n",
    "    for l1 in lams1:\n",
    "        for l2 in lams2: \n",
    "            minmse = 10000\n",
    "            presult = []\n",
    "            count = 0\n",
    "            nit = 0\n",
    "            result = []\n",
    "            params = []\n",
    "            try:\n",
    "                params, c,d = fmin_l_bfgs_b(compute_cost, x0=initialg,args=(l1, l2,k, dtrain, ), disp = 0, callback = check)\n",
    "                params[:] = presult\n",
    "            except ConvergedException:\n",
    "                params[:] = result\n",
    "            print 'converged' + str(nit)\n",
    "            print \"lambda \"+ '\"' +  str(l1) + '\" -> \"' + str(l2) + '\" : ' + ' ' + str(mse(params, k, dtest))\n",
    "            for i, v in enumerate(params):\n",
    "                writer.writerow({'lambda1': l1, 'lambda2': l2,  'k': k, 'value': v})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = defaultdict(lambda: defaultdict(list))\n",
    "with open('Regression baseline - Adjacent pair wise genre bias terms 100 core more.csv', 'rb') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        params[(float(row['lambda1']), float(row['lambda2']))][int(row['k'])].append(float(row['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10.0, 1000.0) 0.753286957465\n",
      "(10.0, 0.01) 0.766684247062\n",
      "(10.0, 0.001) 0.766658491669\n",
      "(10.0, 100.0) 0.753114112668\n",
      "(10.0, 10.0) 0.756883829114\n",
      "(10.0, 10000.0) 0.754408602709\n",
      "(10.0, 0.1) 0.766381137135\n",
      "(10.0, 0.0001) 0.766260425001\n",
      "(10.0, 1.0) 0.76430908397\n",
      "(10.0, 100000.0) 0.754930544152\n",
      "(10.0, 0.0) 0.766153915529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, (10.0, 100.0), 0.76892429610416935)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = list()\n",
    "minCost = 1000000000\n",
    "predictions = []\n",
    "for l in params:\n",
    "    for k in params[l]:\n",
    "        c = mse(params[l][k], k, dvalid)\n",
    "#         print l, k, c\n",
    "        print l, mse(params[l][k], k, dtest)\n",
    "        if c < minCost:\n",
    "            minCost = c\n",
    "            minlambda = l\n",
    "            mink = k\n",
    "            op[:] = params[l][k]\n",
    "mink, minlambda, minCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open(\"Adjacent Model Optimized Parameters.csv\", \"wb\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     for o in op:\n",
    "#         writer.writerow([o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op = []\n",
    "with open(\"Adjacent Model Optimized Parameters.csv\", 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        op.append(float(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.753114112668\n",
      "R Squared Statistic: 0.76665385043\n"
     ]
    }
   ],
   "source": [
    "print \"mse: \" + str(mse(op,k,dtest))\n",
    "print \"R Squared Statistic: \" + str( mse(op, k, dtest) /float(variance(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58041664199319487"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(params[(10,0)][10], k, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usergenres = defaultdict(lambda: set())\n",
    "for u in useritems:\n",
    "    for i in useritems[u]:\n",
    "        cat = getCategory(i, categories, catindex, 3)\n",
    "        if gethexdig(cat) not in ghashed:\n",
    "            cat = 'Anything'\n",
    "        usergenres[u].add(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "lams2 = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "\n",
    "x = lams2\n",
    "y = [0.777347003886, 0.777518819439, 0.777791524404, 0.776386939524, 0.776732703502, 0.776313685638, 0.770003419702, 0.76692445357,\n",
    "    0.767260668956, 0.767691347886, 0.807221417837]\n",
    "# color = ['blue'] * 7 + ['red'] + ['blue'] * 3\n",
    "plt.scatter(lams2[7], y[7], color = 'black', s = 100, marker=\"o\")\n",
    "plt.semilogx(x, y, color = 'red')\n",
    "# legend = plt.legend(loc='upper right', shadow=True, fontsize='large')\n",
    "plt.xlabel('Lambda Value For Adjacent Genre Bias Terms')\n",
    "plt.ylabel('mse on Validation Set')\n",
    "plt.title(\"Adjacent Pairwise Genre Bias Terms Model Regularization Graph\")\n",
    "plt.show()\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# params, c,d = fmin_l_bfgs_b(compute_cost, x0=initialg,args=(0,0,10, dtrain, ), disp = 0)\n",
    "# mse(params,k, dtrain), mse(params,k, dvalid), mse(params,k, dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = op\n",
    "alphao = params[0]\n",
    "betauo = params[1: len(users)+1]\n",
    "end = len(users)+1\n",
    "betaio = params[end: end+len(products)]\n",
    "end = end+len(products)\n",
    "bij = np.array(params[end: end+(gside**2)])\n",
    "betaggo = bij.reshape(gside, gside)\n",
    "end = end + (gside**2)\n",
    "gs = np.array(params[end:])\n",
    "gr = gs.reshape(len(users)+len(products),k)\n",
    "gammuo = gr[:len(users),:]\n",
    "gammio = gr[len(users):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A1G37DFO8MQW0M', 'B000BSF4ES', 5.0, '1311984000')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_names = defaultdict(str)\n",
    "with open('100 core subset filtered.csv', 'rb') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        product_names[row['pid']] = row['ptitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ratings_with_time = defaultdict(lambda: list())\n",
    "user_ratings = defaultdict(lambda: list())\n",
    "for d in data:\n",
    "    user_ratings_with_time[d[0]].append((d[1], int(d[3])))\n",
    "\n",
    "for u in user_ratings_with_time:\n",
    "    items = user_ratings_with_time[u]\n",
    "    isorted = sorted(items, key = lambda tup: tup[1])\n",
    "    user_ratings_with_time[u] = isorted\n",
    "    user_ratings[u] = [i[0] for i in isorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns both items user has rated but not yet at this point in time and items not rated at all \n",
    "def get_products_not_rated(user, time):\n",
    "    items = user_ratings_with_time[user]\n",
    "    not_rated_yet = []\n",
    "    for i,p in enumerate(items):\n",
    "        if p[1] > int(time) and i > 0:\n",
    "            not_rated_yet.extend([j[0] for j in items[i:]])\n",
    "            break\n",
    "    return ps.difference(user_ratings[user]).union(set(not_rated_yet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_items_rated_in_future(user, time, pnames):\n",
    "    items = user_ratings_with_time[user]\n",
    "    not_rated_yet = []\n",
    "    for i,p in enumerate(items):\n",
    "        if p[1] > int(time) and i > 0:\n",
    "            not_rated_yet.extend([j[0] for j in items[i:]])\n",
    "            break\n",
    "    names = []\n",
    "    for n in not_rated_yet:\n",
    "        names.append(pnames[n])\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get_items_rated_in_future(user, time, product_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_item_last_rated(user, time):\n",
    "    items = user_ratings_with_time[user]\n",
    "    for i,p in enumerate(items):\n",
    "        if p[1] >= int(time) and i > 0:\n",
    "            return getCategory(items[i-1][0], categories,catindex, 3)\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This user read harry potter at this unix time\n",
    "user = 'ABMX8XUNPR3LP'\n",
    "time = '1265587200'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Literature & Fiction'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_item_last_rated(user,time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "007141858X\n"
     ]
    }
   ],
   "source": [
    "inr = list(get_products_not_rated(user,time))\n",
    "print inr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def getTopNRecommendations(user,time, n, pnames, params, k):\n",
    "    alphao = params[0]\n",
    "    betauo = params[1: len(users)+1]\n",
    "    end = len(users)+1\n",
    "    betaio = params[end: end+len(products)]\n",
    "    end = end+len(products)\n",
    "    bij = np.array(params[end: end+(gside**2)])\n",
    "    betaggo = bij.reshape(gside, gside)\n",
    "    end = end + (gside**2)\n",
    "    gs = np.array(params[end:])\n",
    "    gr = gs.reshape(len(users)+len(products),k)\n",
    "    gammuo = gr[:len(users),:]\n",
    "    gammio = gr[len(users):,:]\n",
    "    rankings = defaultdict(float)\n",
    "    inr = get_products_not_rated(user,time)\n",
    "    pcat = get_item_last_rated(user,time)\n",
    "    for r in inr:\n",
    "        ccat = getCategory(r, categories, catindex, 3)\n",
    "        pred = alphao + betauo[users[user]] + betaio[products[r]] + (gammuo[users[user]].T.dot(gammio[products[r]]))\n",
    "        if pcat!='':\n",
    "            pred += betaggo[genres[pcat]][genres[ccat]]\n",
    "        rankings[r] = pred\n",
    "    rs = sorted(rankings.iteritems(), key = operator.itemgetter(1), reverse= True)[:n]\n",
    "    names = []\n",
    "    for r in rs:\n",
    "#         if pnames[r[0]] == '':\n",
    "#             print r[0]\n",
    "        names.append(pnames[r[0]])\n",
    "    return names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recs = getTopNRecommendations(user,time, 30, product_names, op, mink)\n",
    "# for r in recs:\n",
    "#     print str(r) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for p in user_ratings[user]:\n",
    "#     print getCategory(p, categories,catindex, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World War Z: An Oral History of the Zombie War\n",
      "The Giver\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "nyr = get_items_rated_in_future(user, time, product_names)\n",
    "for r in recs:\n",
    "    if r in nyr:\n",
    "        print r\n",
    "        count+=1\n",
    "if count == len(nyr):\n",
    "    print True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How to Talk to Anyone: 92 Little Tricks for Big Success in Relationships'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_names['007141858X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getTopNRecommendations_genres(user,time, 20, op, mink)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "pgi = defaultdict(float)\n",
    "for p in products:\n",
    "    cat = getCategory(p, categories,catindex,2)\n",
    "#     if gethexdig(cat) not in ghashed:\n",
    "#         cat = dg\n",
    "#     pgi[product_names[p]] = gammio[products[p]][4]\n",
    "    pgi[cat] = gammio[products[p]][4]\n",
    "#     c+=1\n",
    "#     if c == 20:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pgiSorted = dict(sorted(pgi.iteritems(), key = operator.itemgetter(1), reverse=True)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arts & Photography': 0.0,\n",
       " 'Biographies & Memoirs': 0.00066797175782883013,\n",
       " 'Books': 0.0013545588271336941,\n",
       " \"Children's Books\": 0.011659103027814083,\n",
       " 'Christian Books & Bibles': 0.0,\n",
       " 'Cookbooks': 0.0,\n",
       " 'Law': 0.006977030877938232,\n",
       " 'Literature & Fiction': 0.024345373331861892,\n",
       " 'Makeup': 0.0013938394865582507,\n",
       " 'Medical Books': 0.0,\n",
       " 'Mystery': 0.0,\n",
       " 'New': -0.00036024999434565799,\n",
       " 'Politics & Social Sciences': 0.0019258073819532679,\n",
       " 'Professional & Technical': 0.0,\n",
       " 'Religion & Spirituality': 0.0010990861845958876,\n",
       " 'Science & Math': 0.043528131343161497,\n",
       " 'Science Fiction & Fantasy': 0.0017927081948150771,\n",
       " 'Self-Help': 0.0,\n",
       " 'Teens': 0.015424787999956566,\n",
       " 'Travel': 0.0}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgiSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i, p in enumerate(pgiSorted[:10]):\n",
    "#     print p[0][0], ' : ', p[0][1], ' - ', p[0][2],   '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "frame = pd.DataFrame(data=pgiSorted,index= range(1), dtype=float)\n",
    "frame = frame.fillna(value=0)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask = np.zeros_like(frame, dtype=np.bool)\n",
    "for i in range(frame.shape[0]):\n",
    "    for j in range(frame.shape[1]):\n",
    "        if frame.columns[j] == frame.index[i]:\n",
    "            mask[i,j] = True\n",
    "\n",
    "with sns.axes_style('whitegrid'):\n",
    "    ax = sns.heatmap(frame, mask=mask,center= 0,  robust=True,linewidths=0.5)\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=90)\n",
    "fig = plt.gcf()\n",
    "plt.title('Adjacent Migrations - depth: '+ str(depth))\n",
    "fig.subplots_adjust(bottom=0.3, left = 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeNumericalGradient(params,grad, lam,k, data):\n",
    "    e = 1e-4\n",
    "    numgrads = np.zeros(len(params))\n",
    "    pp = np.zeros(len(params))\n",
    "    for i,p in enumerate(params):\n",
    "        pp[i] = e\n",
    "        loss1,_ = compute_cost(params-pp, lam, k,data)\n",
    "        loss2,_ = compute_cost(params+pp, lam,k, data)\n",
    "#         print loss1, loss2\n",
    "        numgrads[i] = (loss2 - loss1) / float(2*e)\n",
    "        pp[i] = 0\n",
    "        print round(numgrads[i], 3), round(grad[i], 3)\n",
    "#         print abs(numgrads[i]-grad[i])\n",
    "    return numgrads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_genre_from_id(i):\n",
    "    for g in genres:\n",
    "        if genres[g] == i:\n",
    "            return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggbias = defaultdict(int)\n",
    "ggbiasd = defaultdict(lambda: defaultdict(int))\n",
    "for i in range(len(betaggo)):\n",
    "    for j in range(len(betaggo[i])):\n",
    "        g1 = get_genre_from_id(i)\n",
    "        g2 = get_genre_from_id(j)\n",
    "        ggbias[(g1,g2)] = betaggo[i][j]\n",
    "        ggbiasd[g1][g2] = betaggo[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorted(ggbias.iteritems(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "frame = pd.DataFrame.from_dict(data=ggbiasd, dtype=float)\n",
    "frame = frame.fillna(value=0)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask = np.zeros_like(frame, dtype=np.bool)\n",
    "for i in range(frame.shape[0]):\n",
    "    for j in range(frame.shape[1]):\n",
    "        if frame.columns[j] == frame.index[i]:\n",
    "            mask[i,j] = True\n",
    "\n",
    "with sns.axes_style('whitegrid'):\n",
    "    ax = sns.heatmap(frame, mask=mask,center= 0,  robust=True,linewidths=0.5)\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=90)\n",
    "fig = plt.gcf()\n",
    "plt.title('Adjacent Migrations - depth: '+ str(depth))\n",
    "fig.subplots_adjust(bottom=0.3, left = 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.savefig(\"From Model Adjacent Migrations.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# params = op\n",
    "# alphao = params[0]\n",
    "# betauo = params[1: len(users)+1]\n",
    "# end = len(users)+1\n",
    "# betaio = params[end: end+len(products)]\n",
    "# end = end+len(products)\n",
    "# bij = np.array(params[end: end+(gside**2)])\n",
    "# betaggo = bij.reshape(gside, gside)\n",
    "# end = end + (gside**2)\n",
    "# gs = np.array(params[end:])\n",
    "# gr = gs.reshape(len(users)+len(products),k)\n",
    "# gammuo = gr[:len(users),:]\n",
    "# gammio = gr[len(users):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(initial,lam,k, data):\n",
    "    alpha = initial[0]\n",
    "    betau = initial[1:len(users) + 1]\n",
    "    end = len(users)+1\n",
    "    betai = initial[end:end + len(products)]\n",
    "    end = end + len(products)\n",
    "    bij = np.array(initial[end: end+(gside**2)])\n",
    "    betagg = bij.reshape(gside, gside)\n",
    "    end = end + (gside**2)\n",
    "    gss = np.array(initial[end:])\n",
    "    gr = gss.reshape(len(users)+len(products),k)\n",
    "    gammu = gr[:len(users),:]\n",
    "    gammi = gr[len(users):,:]\n",
    "    ga = 0\n",
    "    gbu = np.zeros(len(users))\n",
    "    gbi = np.zeros(len(products))\n",
    "    ggu = np.zeros((len(users),k))\n",
    "    ggi = np.zeros((len(products),k))\n",
    "    gbgg = np.zeros((gside, gside))\n",
    "    for d in data:\n",
    "        term = (alpha + betau[users[d[0]]] + betai[products[d[1]]] + (gammu[users[d[0]]].T.dot(gammi[products[d[1]]])) - d[2])\n",
    "        for i in xrange(4, len(d)):\n",
    "            term += betagg[genres[d[i]]][genres[d[3]]]\n",
    "        ga+= 2 * term\n",
    "        gbu[users[d[0]]] += 2 * term\n",
    "        gbi[products[d[1]]] += 2 * term\n",
    "        ggu[users[d[0]]] += 2 * gammi[products[d[1]]] * term\n",
    "        ggi[products[d[1]]] += 2 * gammu[users[d[0]]] * term\n",
    "        for i in xrange(4, len(d)):\n",
    "            gbgg[genres[d[i]]][genres[d[3]]] += 2* term\n",
    "    for u in us:\n",
    "        gbu[users[u]] += 2 * lam * betau[users[u]]\n",
    "        ggu[users[u]] += 2 * lam * gammu[users[u]]\n",
    "    for p in ps:\n",
    "        gbi[products[p]] += 2 * lam * betai[products[p]]\n",
    "        ggi[products[p]] += 2 * lam * gammi[products[p]]\n",
    "#     for g in gs:\n",
    "#         gbgg[genres[g[0]]][genres[g[1]]] += 2 * 1000 * betagg[genres[g[0]]][genres[g[1]]]\n",
    "    return np.array([ga] + list(gbu) + list(gbi) + list(gbgg.flatten()) + list(ggu.flatten())+ list(ggi.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeNumericalGradient(params,grad, lam,k, data):\n",
    "    e = 1e-4\n",
    "    numgrads = np.zeros(len(params))\n",
    "    pp = np.zeros(len(params))\n",
    "    for i,p in enumerate(params):\n",
    "        pp[i] = e\n",
    "        loss1, _ = compute_cost(params-pp, lam, k,data)\n",
    "        loss2, _ = compute_cost(params+pp, lam,k, data)\n",
    "#         print loss1, loss2\n",
    "        numgrads[i] = (loss2 - loss1) / float(2*e)\n",
    "        pp[i] = 0\n",
    "        print round(numgrads[i], 3), round(grad[i], 3)\n",
    "#         print abs(numgrads[i]-grad[i])\n",
    "    return numgrads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.461 -1.461\n",
      "-0.417 -0.417\n",
      "1.246 1.246\n",
      "-0.48 -0.48\n",
      "-1.568 -1.568\n",
      "0.135 0.135\n",
      "-0.099 -0.099\n",
      "-1.146 -1.146\n",
      "1.452 1.452\n",
      "-0.051 -0.051\n",
      "-0.784 -0.784\n",
      "0.115 0.115\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.151 -0.151\n",
      "0.103 0.103\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.012 -0.012\n",
      "0.137 0.137\n",
      "0.276 0.276\n",
      "0.025 0.025\n",
      "0.429 0.429\n",
      "-0.077 -0.077\n",
      "-0.037 -0.037\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.058 -0.058\n",
      "-0.173 -0.173\n",
      "0.0 0.0\n",
      "0.246 0.246\n",
      "-0.369 -0.369\n",
      "-0.142 -0.142\n",
      "-0.085 -0.085\n",
      "-0.08 -0.08\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.287 0.287\n",
      "0.0 0.0\n",
      "0.2 0.2\n",
      "-0.077 -0.077\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.029 0.029\n",
      "0.0 0.0\n",
      "-0.368 -0.368\n",
      "0.042 0.042\n",
      "-0.188 -0.188\n",
      "-0.215 -0.215\n",
      "0.0 0.0\n",
      "-0.127 -0.127\n",
      "-0.052 -0.052\n",
      "0.151 0.151\n",
      "-0.151 -0.151\n",
      "-0.082 -0.082\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.102 0.102\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.272 0.272\n",
      "-0.247 -0.247\n",
      "0.0 0.0\n",
      "-0.576 -0.576\n",
      "0.0 0.0\n",
      "0.286 0.286\n",
      "-0.377 -0.377\n",
      "-0.1 -0.1\n",
      "0.123 0.123\n",
      "0.0 0.0\n",
      "0.17 0.17\n",
      "0.055 0.055\n",
      "0.0 0.0\n",
      "-0.075 -0.075\n",
      "0.0 0.0\n",
      "-0.303 -0.303\n",
      "0.03 0.03\n",
      "0.0 0.0\n",
      "-0.019 -0.019\n",
      "-0.353 -0.353\n",
      "-0.214 -0.214\n",
      "0.0 0.0\n",
      "0.185 0.185\n",
      "0.294 0.294\n",
      "0.0 0.0\n",
      "0.084 0.084\n",
      "0.063 0.063\n",
      "0.377 0.377\n",
      "0.083 0.083\n",
      "0.422 0.422\n",
      "-0.067 -0.067\n",
      "0.048 0.048\n",
      "0.0 0.0\n",
      "0.159 0.159\n",
      "-0.006 -0.006\n",
      "-0.24 -0.24\n",
      "0.151 0.151\n",
      "0.165 0.165\n",
      "0.0 0.0\n",
      "-0.119 -0.119\n",
      "0.09 0.09\n",
      "-0.36 -0.36\n",
      "0.292 0.292\n",
      "0.0 0.0\n",
      "0.002 0.002\n",
      "-0.038 -0.038\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.092 -0.092\n",
      "-0.244 -0.244\n",
      "0.0 0.0\n",
      "0.128 0.128\n",
      "0.0 0.0\n",
      "-0.02 -0.02\n",
      "0.0 0.0\n",
      "-0.011 -0.011\n",
      "-0.387 -0.387\n",
      "0.0 0.0\n",
      "-0.014 -0.014\n",
      "0.0 0.0\n",
      "-0.055 -0.055\n",
      "0.0 0.0\n",
      "-0.091 -0.091\n",
      "0.126 0.126\n",
      "-0.038 -0.038\n",
      "-0.257 -0.257\n",
      "-0.204 -0.204\n",
      "0.0 0.0\n",
      "-0.028 -0.028\n",
      "-0.068 -0.068\n",
      "-0.539 -0.539\n",
      "0.13 0.13\n",
      "0.0 0.0\n",
      "0.138 0.138\n",
      "0.07 0.07\n",
      "0.025 0.025\n",
      "0.232 0.232\n",
      "-0.004 -0.004\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.082 -0.082\n",
      "0.0 0.0\n",
      "-0.092 -0.092\n",
      "-0.364 -0.364\n",
      "0.329 0.329\n",
      "0.418 0.418\n",
      "-0.004 -0.004\n",
      "-0.184 -0.184\n",
      "0.496 0.496\n",
      "0.129 0.129\n",
      "0.315 0.315\n",
      "0.143 0.143\n",
      "0.085 0.085\n",
      "0.348 0.348\n",
      "-0.114 -0.114\n",
      "0.096 0.096\n",
      "-0.32 -0.32\n",
      "0.281 0.281\n",
      "-0.071 -0.071\n",
      "-0.334 -0.334\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.268 -0.268\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.035 -0.035\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.015 0.015\n",
      "-0.423 -0.423\n",
      "0.0 0.0\n",
      "-0.063 -0.063\n",
      "0.0 0.0\n",
      "0.002 0.002\n",
      "-0.166 -0.166\n",
      "-0.188 -0.188\n",
      "-0.104 -0.104\n",
      "0.07 0.07\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.116 -0.116\n",
      "-0.254 -0.254\n",
      "0.182 0.182\n",
      "0.0 0.0\n",
      "0.369 0.369\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.174 -0.174\n",
      "0.247 0.247\n",
      "-0.263 -0.263\n",
      "0.014 0.014\n",
      "0.0 0.0\n",
      "-0.106 -0.106\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.486 0.486\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.13 -0.13\n",
      "-0.23 -0.23\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.077 -0.077\n",
      "-0.229 -0.229\n",
      "0.112 0.112\n",
      "0.121 0.121\n",
      "-0.018 -0.018\n",
      "0.12 0.12\n",
      "0.087 0.087\n",
      "0.358 0.358\n",
      "0.079 0.079\n",
      "-0.392 -0.392\n",
      "0.304 0.304\n",
      "-0.406 -0.406\n",
      "0.0 0.0\n",
      "-0.264 -0.264\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.065 -0.065\n",
      "-0.19 -0.19\n",
      "0.158 0.158\n",
      "0.046 0.046\n",
      "-0.238 -0.238\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.099 -0.099\n",
      "-0.083 -0.083\n",
      "0.334 0.334\n",
      "-0.08 -0.08\n",
      "-0.209 -0.209\n",
      "-0.06 -0.06\n",
      "0.0 0.0\n",
      "0.294 0.294\n",
      "-0.055 -0.055\n",
      "-0.194 -0.194\n",
      "0.215 0.215\n",
      "0.285 0.285\n",
      "0.0 0.0\n",
      "0.183 0.183\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.195 0.195\n",
      "-0.09 -0.09\n",
      "-0.052 -0.052\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.223 0.223\n",
      "0.122 0.122\n",
      "-0.099 -0.099\n",
      "0.0 0.0\n",
      "-0.048 -0.048\n",
      "-0.004 -0.004\n",
      "0.0 0.0\n",
      "0.073 0.073\n",
      "-0.22 -0.22\n",
      "0.18 0.18\n",
      "-0.005 -0.005\n",
      "0.014 0.014\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.188 -0.188\n",
      "-0.134 -0.134\n",
      "0.073 0.073\n",
      "0.0 0.0\n",
      "-0.04 -0.04\n",
      "0.109 0.109\n",
      "-0.261 -0.261\n",
      "0.0 0.0\n",
      "0.1 0.1\n",
      "0.172 0.172\n",
      "0.088 0.088\n",
      "0.072 0.072\n",
      "0.0 0.0\n",
      "-0.169 -0.169\n",
      "0.185 0.185\n",
      "0.0 0.0\n",
      "0.151 0.151\n",
      "0.0 0.0\n",
      "-0.127 -0.127\n",
      "0.168 0.168\n",
      "0.214 0.214\n",
      "-0.256 -0.256\n",
      "-0.01 -0.01\n",
      "0.172 0.172\n",
      "0.0 0.0\n",
      "0.086 0.086\n",
      "0.018 0.018\n",
      "0.023 0.023\n",
      "0.0 0.0\n",
      "-0.12 -0.12\n",
      "-0.192 -0.192\n",
      "-0.146 -0.146\n",
      "0.0 0.0\n",
      "-0.211 -0.211\n",
      "0.0 0.0\n",
      "0.127 0.127\n",
      "-0.056 -0.056\n",
      "0.065 0.065\n",
      "0.053 0.053\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.26 -0.26\n",
      "0.045 0.045\n",
      "0.0 0.0\n",
      "-0.117 -0.117\n",
      "-0.145 -0.145\n",
      "0.122 0.122\n",
      "-0.275 -0.275\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.055 0.055\n",
      "-0.279 -0.279\n",
      "0.197 0.197\n",
      "0.058 0.058\n",
      "-0.303 -0.303\n",
      "0.0 0.0\n",
      "-0.068 -0.068\n",
      "-0.077 -0.077\n",
      "0.0 0.0\n",
      "-0.188 -0.188\n",
      "-0.229 -0.229\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.552 0.552\n",
      "-0.091 -0.091\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.01 -0.01\n",
      "0.0 0.0\n",
      "-0.083 -0.083\n",
      "0.0 0.0\n",
      "-0.024 -0.024\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.081 0.081\n",
      "-0.195 -0.195\n",
      "0.0 0.0\n",
      "-0.121 -0.121\n",
      "0.15 0.15\n",
      "0.257 0.257\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.085 0.085\n",
      "0.482 0.482\n",
      "-0.008 -0.008\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.132 -0.132\n",
      "0.154 0.154\n",
      "0.523 0.523\n",
      "-0.301 -0.301\n",
      "0.344 0.344\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.457 0.457\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.461 0.461\n",
      "-0.199 -0.199\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.04 0.04\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.184 0.184\n",
      "0.199 0.199\n",
      "-0.247 -0.247\n",
      "-0.222 -0.222\n",
      "0.015 0.015\n",
      "0.0 0.0\n",
      "0.033 0.033\n",
      "0.0 0.0\n",
      "-0.105 -0.105\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.272 -0.272\n",
      "0.0 0.0\n",
      "-0.228 -0.228\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.29 -0.29\n",
      "0.025 0.025\n",
      "-0.113 -0.113\n",
      "-0.138 -0.138\n",
      "-0.07 -0.07\n",
      "0.0 0.0\n",
      "0.315 0.315\n",
      "-0.071 -0.071\n",
      "-0.341 -0.341\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.11 0.11\n",
      "0.1 0.1\n",
      "0.459 0.459\n",
      "0.313 0.313\n",
      "-0.05 -0.05\n",
      "-0.062 -0.062\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.11 -0.11\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.065 0.065\n",
      "0.094 0.094\n",
      "0.204 0.204\n",
      "0.164 0.164\n",
      "0.285 0.285\n",
      "0.251 0.251\n",
      "-0.113 -0.113\n",
      "-0.109 -0.109\n",
      "0.0 0.0\n",
      "-0.234 -0.234\n",
      "0.2 0.2\n",
      "-0.036 -0.036\n",
      "0.011 0.011\n",
      "0.16 0.16\n",
      "0.0 0.0\n",
      "-0.204 -0.204\n",
      "-0.003 -0.003\n",
      "0.0 0.0\n",
      "-0.19 -0.19\n",
      "-0.081 -0.081\n",
      "0.038 0.038\n",
      "0.24 0.24\n",
      "0.226 0.226\n",
      "0.129 0.129\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.091 -0.091\n",
      "0.107 0.107\n",
      "0.421 0.421\n",
      "-0.007 -0.007\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.129 -0.129\n",
      "-0.162 -0.162\n",
      "0.069 0.069\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.196 0.196\n",
      "0.05 0.05\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.23 -0.23\n",
      "-0.149 -0.149\n",
      "0.238 0.238\n",
      "-0.426 -0.426\n",
      "0.118 0.118\n",
      "0.0 0.0\n",
      "-0.07 -0.07\n",
      "-0.136 -0.136\n",
      "-0.07 -0.07\n",
      "0.179 0.179\n",
      "0.0 0.0\n",
      "0.259 0.259\n",
      "0.0 0.0\n",
      "-0.045 -0.045\n",
      "0.0 0.0\n",
      "0.473 0.473\n",
      "-0.067 -0.067\n",
      "-0.324 -0.324\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.11 0.11\n",
      "0.169 0.169\n",
      "0.285 0.285\n",
      "0.001 0.001\n",
      "-0.145 -0.145\n",
      "0.164 0.164\n",
      "-0.084 -0.084\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.13 -0.13\n",
      "-0.295 -0.295\n",
      "-0.205 -0.205\n",
      "0.0 0.0\n",
      "-0.197 -0.197\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.031 0.031\n",
      "-0.334 -0.334\n",
      "0.184 0.184\n",
      "0.008 0.008\n",
      "0.076 0.076\n",
      "0.084 0.084\n",
      "-0.275 -0.275\n",
      "0.393 0.393\n",
      "-0.1 -0.1\n",
      "-0.122 -0.122\n",
      "0.0 0.0\n",
      "-0.172 -0.172\n",
      "-0.326 -0.326\n",
      "0.0 0.0\n",
      "-0.04 -0.04\n",
      "0.0 0.0\n",
      "-0.106 -0.106\n",
      "-0.325 -0.325\n",
      "-0.055 -0.055\n",
      "0.566 0.566\n",
      "0.091 0.091\n",
      "0.197 0.197\n",
      "-0.026 -0.026\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.267 0.267\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.152 0.152\n",
      "0.158 0.158\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.151 0.151\n",
      "0.288 0.288\n",
      "0.0 0.0\n",
      "-0.478 -0.478\n",
      "0.292 0.292\n",
      "0.0 0.0\n",
      "-0.184 -0.184\n",
      "0.0 0.0\n",
      "-0.117 -0.117\n",
      "-0.295 -0.295\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.041 0.041\n",
      "-0.305 -0.305\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.066 0.066\n",
      "0.238 0.238\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.196 0.196\n",
      "0.0 0.0\n",
      "-0.23 -0.23\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.366 -0.366\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.071 0.071\n",
      "0.0 0.0\n",
      "-0.229 -0.229\n",
      "0.057 0.057\n",
      "0.0 0.0\n",
      "-0.063 -0.063\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.214 -0.214\n",
      "0.557 0.557\n",
      "0.0 0.0\n",
      "-0.017 -0.017\n",
      "-0.24 -0.24\n",
      "0.0 0.0\n",
      "-0.329 -0.329\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.045 0.045\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.193 0.193\n",
      "-0.088 -0.088\n",
      "0.134 0.134\n",
      "-0.353 -0.353\n",
      "0.211 0.211\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.022 -0.022\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.104 -0.104\n",
      "0.0 0.0\n",
      "0.087 0.087\n",
      "0.008 0.008\n",
      "-0.024 -0.024\n",
      "0.063 0.063\n",
      "0.016 0.016\n",
      "0.444 0.444\n",
      "-0.159 -0.159\n",
      "-0.022 -0.022\n",
      "0.21 0.21\n",
      "0.051 0.051\n",
      "-0.213 -0.213\n",
      "-0.223 -0.223\n",
      "0.0 0.0\n",
      "0.134 0.134\n",
      "-0.102 -0.102\n",
      "-0.028 -0.028\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.048 0.048\n",
      "0.12 0.12\n",
      "0.159 0.159\n",
      "0.0 0.0\n",
      "-0.1 -0.1\n",
      "-0.106 -0.106\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.087 0.087\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.232 0.232\n",
      "-0.404 -0.404\n",
      "0.0 0.0\n",
      "-0.266 -0.266\n",
      "0.055 0.055\n",
      "0.275 0.275\n",
      "-0.118 -0.118\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.14 0.14\n",
      "0.0 0.0\n",
      "0.147 0.147\n",
      "-0.188 -0.188\n",
      "-0.011 -0.011\n",
      "0.0 0.0\n",
      "-0.301 -0.301\n",
      "0.0 0.0\n",
      "0.201 0.201\n",
      "0.034 0.034\n",
      "0.0 0.0\n",
      "0.198 0.198\n",
      "0.0 0.0\n",
      "-0.137 -0.137\n",
      "0.073 0.073\n",
      "0.0 0.0\n",
      "0.021 0.021\n",
      "0.226 0.226\n",
      "0.0 0.0\n",
      "0.264 0.264\n",
      "0.0 0.0\n",
      "0.004 0.004\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.174 -0.174\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.074 0.074\n",
      "0.109 0.109\n",
      "0.409 0.409\n",
      "0.0 0.0\n",
      "-0.052 -0.052\n",
      "0.005 0.005\n",
      "-0.022 -0.022\n",
      "0.118 0.118\n",
      "0.32 0.32\n",
      "0.216 0.216\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.081 -0.081\n",
      "0.307 0.307\n",
      "0.289 0.289\n",
      "-0.353 -0.353\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.059 0.059\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.066 -0.066\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.183 -0.183\n",
      "0.139 0.139\n",
      "-0.074 -0.074\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.067 -0.067\n",
      "0.111 0.111\n",
      "0.093 0.093\n",
      "-0.262 -0.262\n",
      "0.025 0.025\n",
      "-0.103 -0.103\n",
      "0.0 0.0\n",
      "-0.081 -0.081\n",
      "0.0 0.0\n",
      "-0.126 -0.126\n",
      "0.298 0.298\n",
      "0.016 0.016\n",
      "0.0 0.0\n",
      "-0.274 -0.274\n",
      "-0.228 -0.228\n",
      "-0.324 -0.324\n",
      "0.0 0.0\n",
      "-0.471 -0.471\n",
      "0.283 0.283\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.006 -0.006\n",
      "0.087 0.087\n",
      "0.095 0.095\n",
      "-0.091 -0.091\n",
      "-0.229 -0.229\n",
      "0.343 0.343\n",
      "-0.09 -0.09\n",
      "0.0 0.0\n",
      "0.131 0.131\n",
      "0.22 0.22\n",
      "0.151 0.151\n",
      "0.311 0.311\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.021 -0.021\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.238 0.238\n",
      "0.0 0.0\n",
      "-0.004 -0.004\n",
      "0.0 0.0\n",
      "-0.111 -0.111\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.031 0.031\n",
      "0.387 0.387\n",
      "0.0 0.0\n",
      "0.289 0.289\n",
      "0.0 0.0\n",
      "0.362 0.362\n",
      "-0.068 -0.068\n",
      "0.0 0.0\n",
      "0.11 0.11\n",
      "0.377 0.377\n",
      "0.344 0.344\n",
      "0.0 0.0\n",
      "0.123 0.123\n",
      "0.0 0.0\n",
      "0.138 0.138\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.076 0.076\n",
      "0.234 0.234\n",
      "-0.038 -0.038\n",
      "0.0 0.0\n",
      "-0.02 -0.02\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.185 -0.185\n",
      "0.0 0.0\n",
      "-0.04 -0.04\n",
      "-0.493 -0.493\n",
      "0.0 0.0\n",
      "-0.145 -0.145\n",
      "0.008 0.008\n",
      "0.257 0.257\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.164 0.164\n",
      "-0.151 -0.151\n",
      "0.053 0.053\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.164 -0.164\n",
      "0.0 0.0\n",
      "-0.247 -0.247\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.316 0.316\n",
      "0.0 0.0\n",
      "-0.047 -0.047\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.005 0.005\n",
      "0.0 0.0\n",
      "0.252 0.252\n",
      "0.121 0.121\n",
      "0.262 0.262\n",
      "0.137 0.137\n",
      "0.143 0.143\n",
      "0.062 0.062\n",
      "-0.159 -0.159\n",
      "-0.396 -0.396\n",
      "0.025 0.025\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.206 0.206\n",
      "0.025 0.025\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.261 -0.261\n",
      "0.03 0.03\n",
      "-0.337 -0.337\n",
      "-0.346 -0.346\n",
      "0.209 0.209\n",
      "0.0 0.0\n",
      "-0.212 -0.212\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.089 -0.089\n",
      "0.023 0.023\n",
      "0.332 0.332\n",
      "0.181 0.181\n",
      "0.171 0.171\n",
      "0.295 0.295\n",
      "-0.011 -0.011\n",
      "0.0 0.0\n",
      "0.017 0.017\n",
      "0.0 0.0\n",
      "0.088 0.088\n",
      "-0.288 -0.288\n",
      "0.0 0.0\n",
      "0.032 0.032\n",
      "0.072 0.072\n",
      "0.254 0.254\n",
      "0.002 0.002\n",
      "0.383 0.383\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.272 -0.272\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.292 0.292\n",
      "-0.016 -0.016\n",
      "-0.153 -0.153\n",
      "0.049 0.049\n",
      "-0.556 -0.556\n",
      "0.146 0.146\n",
      "0.0 0.0\n",
      "-0.005 -0.005\n",
      "0.0 0.0\n",
      "-0.062 -0.062\n",
      "-0.247 -0.247\n",
      "0.112 0.112\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.363 -0.363\n",
      "0.0 0.0\n",
      "0.354 0.354\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.315 0.315\n",
      "-0.027 -0.027\n",
      "0.0 0.0\n",
      "0.035 0.035\n",
      "0.0 0.0\n",
      "-0.096 -0.096\n",
      "0.251 0.251\n",
      "0.0 0.0\n",
      "-0.044 -0.044\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.521 0.521\n",
      "0.0 0.0\n",
      "-0.11 -0.11\n",
      "0.365 0.365\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.236 -0.236\n",
      "0.112 0.112\n",
      "0.014 0.014\n",
      "-0.067 -0.067\n",
      "-0.038 -0.038\n",
      "0.0 0.0\n",
      "-0.243 -0.243\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.106 0.106\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.216 -0.216\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.257 0.257\n",
      "0.0 0.0\n",
      "0.053 0.053\n",
      "0.243 0.243\n",
      "-0.04 -0.04\n",
      "0.084 0.084\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.135 -0.135\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.104 0.104\n",
      "0.263 0.263\n",
      "0.157 0.157\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.007 0.007\n",
      "0.0 0.0\n",
      "0.083 0.083\n",
      "0.262 0.262\n",
      "-0.057 -0.057\n",
      "0.0 0.0\n",
      "-0.02 -0.02\n",
      "0.243 0.243\n",
      "0.0 0.0\n",
      "-0.24 -0.24\n",
      "-0.244 -0.244\n",
      "0.126 0.126\n",
      "-0.034 -0.034\n",
      "-0.077 -0.077\n",
      "-0.222 -0.222\n",
      "0.308 0.308\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.014 -0.014\n",
      "0.344 0.344\n",
      "0.056 0.056\n",
      "0.052 0.052\n",
      "0.35 0.35\n",
      "0.438 0.438\n",
      "0.302 0.302\n",
      "-0.076 -0.076\n",
      "-0.184 -0.184\n",
      "0.0 0.0\n",
      "-0.217 -0.217\n",
      "-0.046 -0.046\n",
      "0.0 0.0\n",
      "0.187 0.187\n",
      "0.267 0.267\n",
      "0.0 0.0\n",
      "-0.035 -0.035\n",
      "0.074 0.074\n",
      "-0.178 -0.178\n",
      "-0.038 -0.038\n",
      "-0.239 -0.239\n",
      "-0.17 -0.17\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.069 -0.069\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.091 -0.091\n",
      "-0.17 -0.17\n",
      "-0.064 -0.064\n",
      "-0.126 -0.126\n",
      "-0.031 -0.031\n",
      "0.0 0.0\n",
      "0.249 0.249\n",
      "-0.397 -0.397\n",
      "0.191 0.191\n",
      "0.0 0.0\n",
      "-0.251 -0.251\n",
      "0.245 0.245\n",
      "0.014 0.014\n",
      "-0.239 -0.239\n",
      "0.049 0.049\n",
      "0.35 0.35\n",
      "-0.313 -0.313\n",
      "0.0 0.0\n",
      "-0.004 -0.004\n",
      "-0.01 -0.01\n",
      "-0.043 -0.043\n",
      "0.123 0.123\n",
      "0.234 0.234\n",
      "0.219 0.219\n",
      "0.041 0.041\n",
      "0.019 0.019\n",
      "0.0 0.0\n",
      "0.042 0.042\n",
      "-0.003 -0.003\n",
      "0.0 0.0\n",
      "-0.231 -0.231\n",
      "0.386 0.386\n",
      "-0.144 -0.144\n",
      "0.081 0.081\n",
      "0.191 0.191\n",
      "0.04 0.04\n",
      "0.09 0.09\n",
      "-0.303 -0.303\n",
      "-0.336 -0.336\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.042 -0.042\n",
      "0.0 0.0\n",
      "0.101 0.101\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.148 0.148\n",
      "0.0 0.0\n",
      "-0.003 -0.003\n",
      "0.0 0.0\n",
      "-0.006 -0.006\n",
      "0.071 0.071\n",
      "0.0 0.0\n",
      "0.306 0.306\n",
      "0.0 0.0\n",
      "0.218 0.218\n",
      "-0.249 -0.249\n",
      "0.185 0.185\n",
      "0.391 0.391\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.033 0.033\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.143 -0.143\n",
      "0.259 0.259\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.066 -0.066\n",
      "0.127 0.127\n",
      "0.157 0.157\n",
      "0.0 0.0\n",
      "0.012 0.012\n",
      "-0.061 -0.061\n",
      "-0.329 -0.329\n",
      "-0.079 -0.079\n",
      "0.261 0.261\n",
      "-0.113 -0.113\n",
      "0.296 0.296\n",
      "0.0 0.0\n",
      "0.305 0.305\n",
      "0.065 0.065\n",
      "-0.22 -0.22\n",
      "-0.123 -0.123\n",
      "0.0 0.0\n",
      "-0.262 -0.262\n",
      "-0.261 -0.261\n",
      "0.277 0.277\n",
      "-0.372 -0.372\n",
      "0.0 0.0\n",
      "-0.339 -0.339\n",
      "0.177 0.177\n",
      "0.144 0.144\n",
      "0.327 0.327\n",
      "-0.227 -0.227\n",
      "0.0 0.0\n",
      "-0.164 -0.164\n",
      "-0.168 -0.168\n",
      "0.343 0.343\n",
      "0.0 0.0\n",
      "0.168 0.168\n",
      "-0.116 -0.116\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.218 0.218\n",
      "-0.035 -0.035\n",
      "0.088 0.088\n",
      "-0.282 -0.282\n",
      "0.286 0.286\n",
      "0.302 0.302\n",
      "-0.272 -0.272\n",
      "0.195 0.195\n",
      "0.096 0.096\n",
      "0.031 0.031\n",
      "0.0 0.0\n",
      "-0.113 -0.113\n",
      "-0.109 -0.109\n",
      "0.0 0.0\n",
      "-0.141 -0.141\n",
      "-0.051 -0.051\n",
      "-0.264 -0.264\n",
      "-0.028 -0.028\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.032 -0.032\n",
      "-0.021 -0.021\n",
      "0.0 0.0\n",
      "-0.089 -0.089\n",
      "0.0 0.0\n",
      "-0.099 -0.099\n",
      "0.096 0.096\n",
      "0.048 0.048\n",
      "0.111 0.111\n",
      "0.021 0.021\n",
      "0.0 0.0\n",
      "-0.148 -0.148\n",
      "0.0 0.0\n",
      "-0.177 -0.177\n",
      "-0.085 -0.085\n",
      "0.315 0.315\n",
      "0.069 0.069\n",
      "-0.065 -0.065\n",
      "0.066 0.066\n",
      "0.139 0.139\n",
      "0.0 0.0\n",
      "-0.207 -0.207\n",
      "-0.687 -0.687\n",
      "0.094 0.094\n",
      "0.149 0.149\n",
      "0.333 0.333\n",
      "0.03 0.03\n",
      "0.079 0.079\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.191 0.191\n",
      "0.239 0.239\n",
      "-0.134 -0.134\n",
      "-0.186 -0.186\n",
      "-0.355 -0.355\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.296 0.296\n",
      "0.0 0.0\n",
      "0.028 0.028\n",
      "0.433 0.433\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.036 -0.036\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.18 0.18\n",
      "0.0 0.0\n",
      "-0.002 -0.002\n",
      "-0.045 -0.045\n",
      "0.0 0.0\n",
      "0.153 0.153\n",
      "0.197 0.197\n",
      "0.0 0.0\n",
      "-0.312 -0.312\n",
      "-0.279 -0.279\n",
      "-0.156 -0.156\n",
      "-0.324 -0.324\n",
      "-0.212 -0.212\n",
      "0.0 0.0\n",
      "-0.036 -0.036\n",
      "0.01 0.01\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.146 0.146\n",
      "0.0 0.0\n",
      "-0.143 -0.143\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.35 -0.35\n",
      "0.14 0.14\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.252 0.252\n",
      "0.259 0.259\n",
      "-0.108 -0.108\n",
      "0.0 0.0\n",
      "-0.232 -0.232\n",
      "0.373 0.373\n",
      "0.051 0.051\n",
      "0.0 0.0\n",
      "-0.016 -0.016\n",
      "-0.055 -0.055\n",
      "-0.19 -0.19\n",
      "-0.38 -0.38\n",
      "-0.322 -0.322\n",
      "-0.044 -0.044\n",
      "0.0 0.0\n",
      "0.257 0.257\n",
      "-0.128 -0.128\n",
      "-0.122 -0.122\n",
      "-0.626 -0.626\n",
      "-0.251 -0.251\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.02 -0.02\n",
      "0.0 0.0\n",
      "-0.199 -0.199\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.145 -0.145\n",
      "0.242 0.242\n",
      "0.0 0.0\n",
      "0.17 0.17\n",
      "0.406 0.406\n",
      "-0.062 -0.062\n",
      "0.0 0.0\n",
      "-0.038 -0.038\n",
      "0.0 0.0\n",
      "-0.011 -0.011\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.1 0.1\n",
      "0.194 0.194\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.187 -0.187\n",
      "0.031 0.031\n",
      "0.029 0.029\n",
      "0.223 0.223\n",
      "-0.211 -0.211\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.165 -0.165\n",
      "0.087 0.087\n",
      "-0.267 -0.267\n",
      "0.0 0.0\n",
      "-0.217 -0.217\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.031 -0.031\n",
      "-0.345 -0.345\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.161 -0.161\n",
      "0.208 0.208\n",
      "-0.369 -0.369\n",
      "0.226 0.226\n",
      "0.279 0.279\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.264 -0.264\n",
      "0.211 0.211\n",
      "-0.022 -0.022\n",
      "-0.017 -0.017\n",
      "0.0 0.0\n",
      "-0.214 -0.214\n",
      "-0.097 -0.097\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.31 -0.31\n",
      "0.188 0.188\n",
      "0.0 0.0\n",
      "0.137 0.137\n",
      "0.097 0.097\n",
      "-0.416 -0.416\n",
      "0.0 0.0\n",
      "0.263 0.263\n",
      "0.047 0.047\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.171 0.171\n",
      "-0.146 -0.146\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.272 0.272\n",
      "0.259 0.259\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.118 -0.118\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.005 0.005\n",
      "-0.013 -0.013\n",
      "0.0 0.0\n",
      "-0.082 -0.082\n",
      "-0.183 -0.183\n",
      "0.345 0.345\n",
      "0.062 0.062\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.029 -0.029\n",
      "0.178 0.178\n",
      "-0.073 -0.073\n",
      "-0.523 -0.523\n",
      "0.208 0.208\n",
      "0.444 0.444\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.154 0.154\n",
      "-0.254 -0.254\n",
      "0.05 0.05\n",
      "0.227 0.227\n",
      "0.0 0.0\n",
      "-0.059 -0.059\n",
      "0.0 0.0\n",
      "0.299 0.299\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "-0.246 -0.246\n",
      "0.0 0.0\n",
      "0.143 0.143\n",
      "0.343 0.343\n",
      "-0.128 -0.128\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.056 0.056\n",
      "-0.361 -0.361\n",
      "0.0 0.0\n",
      "0.04 0.04\n",
      "0.219 0.219\n",
      "0.0 0.0\n",
      "-0.319 -0.319\n",
      "0.0 0.0\n",
      "-0.19 -0.19\n",
      "0.0 0.0\n",
      "0.038 0.038\n",
      "-0.33 -0.33\n",
      "-0.248 -0.248\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.036 0.036\n",
      "0.168 0.168\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-db5fa42eaf15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitialg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcomputeNumericalGradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitialg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-54-2e89cb7d41e2>\u001b[0m in \u001b[0;36mcomputeNumericalGradient\u001b[1;34m(params, grad, lam, k, data)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mpp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mloss1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mloss2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#         print loss1, loss2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-da4ef7bbae27>\u001b[0m in \u001b[0;36mcompute_cost\u001b[1;34m(initial, lam, k, data)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mJ\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlam\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbetau\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgammu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mJ\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[0mlam\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbetai\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mproducts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgammi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mproducts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mJ\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbetagg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgenres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgenres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grad = gradient(initialg, 1,k , dtest[:1])\n",
    "computeNumericalGradient(initialg, grad, 1,k, dtest[:1] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
